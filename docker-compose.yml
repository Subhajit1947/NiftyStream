
version: '3.8'

x-base-service: &base-service
  networks:
    - niftystream-network
services:
  zookeeper:
    <<: *base-service
    image: confluentinc/cp-zookeeper:7.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
  kafka:
    <<: *base-service
    image: confluentinc/cp-kafka:7.5.3
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_CREATE_TOPICS: "raw:1:1"
  postgres:
    <<: *base-service
    build:
      context: .
      dockerfile: ./docker/postgres/Dockerfile
    container_name: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/opt/postgresql/data
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      
  spark-master:
    <<: *base-service
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    container_name: spark-master
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      --host spark-master
      --port 7077
      --webui-port 8080
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      - SPARK_LOCAL_IP=spark-master
      - PYTHONPATH=/opt/apps
      - SPARK_JARS_PACKAGES=org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262
      - HOME=/home/spark
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_URL =${POSTGRES_URL}
      - ALERT_TABLE=${ALERT_TABLE}
      - STOCK_TABLE=${STOCK_TABLE}
    env_file:
      - ./.env 
    volumes:
      - ./processing:/opt/apps

  spark-worker:
    <<: *base-service
    build:
      context: .
      dockerfile: docker/spark/Dockerfile
    container_name: spark-worker
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --cores 2
      --memory 2g
    depends_on:
      - spark-master
    environment:
      - SPARK_LOCAL_IP=spark-worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - PYTHONPATH=/opt/apps/
      - SPARK_JARS_PACKAGES=org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262
      - HOME=/home/spark
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_URL =${POSTGRES_URL}
      - ALERT_TABLE=${ALERT_TABLE}
      - STOCK_TABLE=${STOCK_TABLE}
    env_file:
      - ./.env 
    volumes:
      - ./processing:/opt/apps
  ingestion-service:
    <<: *base-service
    build:
      context: .
      dockerfile: docker/ingestion/Dockerfile
    depends_on:
      - kafka
      # - timescaledb
      # - redis
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      # POSTGRES_CONNECTION: postgresql://admin:password123@timescaledb:5432/niftystream
      # REDIS_URL: redis://:redispass123@redis:6379/0
    volumes:
      - ./ingestion:/app/ingestion
      - ./monitoring:/app/monitoring
    command: >
      sh -c "
      echo 'Waiting 20 seconds for Kafka to be fully ready...' &&
      sleep 20 &&
      echo 'Starting Kafka producer...' &&
      python -m ingestion.kafka_producer
      "
  dashboard:
    <<: *base-service
    build:
      context: .
      dockerfile: docker/dashboard/Dockerfile  # Changed path
    container_name: stock-dashboard
    ports:
      - "8501:8501"  # Streamlit default port
    depends_on:
      - postgres  # Dashboard needs PostgreSQL
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - STREAMLIT_SERVER_PORT=${STREAMLIT_SERVER_PORT}
      - STREAMLIT_SERVER_ADDRESS=${STREAMLIT_SERVER_ADDRESS}
      - STREAMLIT_THEME=${STREAMLIT_THEME}
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=${STREAMLIT_BROWSER_GATHER_USAGE_STATS}
    env_file:
      - ./.env  # For POSTGRES_USER and POSTGRES_PASSWORD
    volumes:
      - ./dashboard:/app/dashboard
    command: >
      sh -c "
      echo 'Waiting for PostgreSQL to be ready...' &&
      sleep 10 &&
      echo 'Starting Streamlit dashboard...' &&
      cd /app/dashboard &&
      streamlit run app.py --server.port=8501 --server.address=0.0.0.0
      "


    
networks:
  niftystream-network:
    driver: bridge

volumes:
  postgres_data: